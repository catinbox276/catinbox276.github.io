---
layout: single
title: "Data Noise"
categories: NLP
tag: [Machine-Learning]
use_math: true
---

# Data Noise

#### Silent Failure (조용한 실패)
시스템이 내부적으로는 잘못된 결과를 내고 있음에도 오류 메시지나 경고 없이 겉보기엔 정상 작동하는 상태이다.

알람이 없으니 문제를 즉시 알아채지 못해 잘못된 의사결정·신뢰도 하락·안전 사고가 연쇄적으로 발생하며, 뒤늦게 발견하면 이미 데이터·모델·비즈니스 지표가 광범위하게 오염돼 복구 비용과 평판 손실이 매우 크다.

***Garbage In → Silent Failure Out***<br>
쓰레기(노이즈)의 출발점이 대부분 데이터 전처리가 원인 이다.

결국, 조용히 문제를 일으키는 Silent Failure의 씨앗은 대부분 전처리 단계에서 생긴 노이즈들입니다.<br>
그렇다면 어떤 종류의 노이즈가 존재하고, 각각을 어떻게 처리해야 할까요?<br>
아래 표에서 주요 노이즈 유형별 특징과 대응 방법을 한눈에 정리해 보았습니다.

### 데이터 다양성 (Diversity, Coverage)
| 개념 | 간단한 설명 | 주로 쓰는 해결 방법 |
|------|-------------|--------------------|
| **다양성 / 커버리지 부족**<br>(Diversity & Coverage) | 데이터가 특정 집단·상황·패턴에 치우쳐 있어 **전체 문제 공간을 충분히 대표하지 못함**. → 모델이 보지 못한 케이스에서 성능 저하·편향(Bias) 발생 | • **샘플링 전략 재점검**: 계층(-stratified)·층화·시계열 구간별 균형 수집<br>• **데이터 증강(Augmentation)**: 이미지 변환, 문장 패러프레이즈, SMOTE 등으로 희소 클래스 보강<br>• **도메인 확장 수집**: 지역·언어·장치·계절 등 변수를 기준으로 의도적 ‘꼭짓점 데이터’ 확보<br>• **가중치 보정**: under-/over-sampling, 클래스 가중치로 학습 편향 완화<br>• **평가 지표 분리**: 서브그룹별 정확도·F1·AUROC을 따로 모니터링하여 결손 영역 탐지<br>• **지속적 데이터 드리프트 모니터링**: 배포 뒤 신규 분포 감지 → 주기적 재학습·데이터 보강 |


## 노이즈 유형 및 대응 가이드
| 노이즈 유형 | 설명 | 주로 쓰는 해결 방법 |
|-------------|------------|--------------------|
| **결측치 (Missing Values)** | 값 자체가 비어 있어 모델이 정보를 얻지 못함 | • 해당 행/열 삭제<br>• 평균·중앙값·모드·KNN 등 **단순/통계적 대체**<br>• **모델 기반** 예측 대체 (MICE 등)<br>• “결측 여부”를 별도 피처로 추가 |
| **이상치 (Outliers)** | 분포에서 멀리 떨어진 극단적 값으로 모델을 왜곡 | • IQRㆍZ-scoreㆍIsolation Forest 등으로 탐지<br>• **입력 오류**면 수동 수정·삭제, 합리적 범위로 클리핑<br>• 로그·Box-Cox 등 **변환**<br>• 트리·Huber loss 같은 **강건 모델** 사용 |
| **틀린 라벨 (Incorrect Labels)** | 정답이 잘못 달려 학습 신호가 오염 | • 표본 추출 후 **수동 재검수**<br>• 다수결·크라우드소싱 등 **다중 주석**<br>• Label smoothing·Confident learning 같은 **노이즈-견고 학습 기법**<br>• 모델 불확실도 활용 **Active learning**으로 의심 샘플 선별 |
| **문제 정의의 모호성 (Ambiguity)** | “정답” 기준이 애매하여 라벨링 일관성 저하 | • **업무 목적 재정의**, 명확한 가이드라인 작성<br>• 도메인 전문가와 정의 재검토 후 **라벨 재작업**<br>• 애매 구간은 “기타/불확실” 클래스로 분리 |
| **중복 샘플 (Duplicate Samples)** | 동일·거의 동일한 레코드가 반복되어 편향 발생 | • 해시·키·유사도(벡터, Levenshtein) 기반 **중복 제거**<br>• 의도적 오버샘플링일 경우 **가중치 조정**으로 균형 유지 |
| **도메인 외 샘플 (Out-of-Domain)** | 훈련·예상 사용 범위를 벗어난 데이터 | • Mahalanobis distance, ODIN, Energy score 등 **OOD 탐지**<br>• 필터링·분리 학습 (특수 클래스 부여) 또는 **데이터 보강**으로 범위 확대<br>• 배포 후 **모니터링**해 지속적 수집·재학습 |



